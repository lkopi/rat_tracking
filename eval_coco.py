#!/usr/bin/env python
# coding: utf-8

import argparse
import os

import numpy as np
import torch

from detectron2.data import build_detection_test_loader
from detectron2.evaluation import COCOEvaluator
from detectron2.structures.boxes import Boxes
from detectron2.structures.instances import Instances

import annotation2coco as a2c
import train_detectron2 as td2
import utils.io


def keypoint2detectron(seg_dir, idx, curr_annot):
    instances = utils.io.read(os.path.join(seg_dir, '{}_instances.png'.format(idx)))
    anns = curr_annot

    inst = Instances(instances.shape)

    scores = []
    pred_classes = []
    pred_boxes = []
    pred_masks = []
    pred_keypoints = []
    for inst_id, keypoints in anns.items():
        instance_mask = (instances == int(inst_id)+1).astype(np.uint8)
        segmentations, area, bbox = a2c.coco_segmentation(instance_mask)
        kp_list = np.asarray([keypoints['head'][::-1] + [0.0],
                              keypoints['tail_base'][::-1] + [0.0],
                              keypoints['tail'][::-1] + [0.0]])
        bx,by,bw,bh = bbox
        bbox = [bx,by,bx+bw,by+bh]
        pred_boxes.append(bbox)
        pred_masks.append(instance_mask)
        pred_keypoints.append(kp_list)
        scores.append(1)
        pred_classes.append(0)

    inst.set('scores', torch.tensor(scores).cuda())
    inst.set('pred_classes', torch.tensor(pred_classes).cuda())
    inst.set('pred_boxes', Boxes(torch.tensor(pred_boxes).cuda()))
    inst.set('pred_masks', torch.tensor(pred_masks, dtype=torch.bool).cuda())
    inst.set('pred_keypoints', torch.tensor(pred_keypoints).cuda())
    return inst


def part2detectron(seg_dir, idx):
    instances = utils.io.read(os.path.join(seg_dir, '{}_instances.png'.format(idx)))
    parts = utils.io.read(os.path.join(seg_dir, '{}_parts.png'.format(idx)))
    part2pid = {'head': 3, 'body': 2, 'tail': 1}
    part2category = {'head': 0, 'body': 1, 'tail': 2}

    inst = Instances(instances.shape)

    scores = []
    pred_classes = []
    pred_boxes = []
    pred_masks = []
    for inst_id in np.unique(instances)[1:]:
        instance_mask = (instances == inst_id).astype(np.uint8)
        for part_name in part2category.keys():
            part_id = part2pid[part_name]
            part_mask = (instance_mask * (parts == part_id)).astype(np.uint8)

            segmentations, area, bbox = a2c.coco_segmentation(part_mask)
            bx,by,bw,bh = bbox
            bbox = [bx,by,bx+bw,by+bh]
            pred_boxes.append(bbox)
            pred_masks.append(instance_mask)
            scores.append(1)
            pred_classes.append(part2category[part_name])

    inst.set('scores', torch.tensor(scores).cuda())
    inst.set('pred_classes', torch.tensor(pred_classes).cuda())
    inst.set('pred_boxes', Boxes(torch.tensor(pred_boxes).cuda()))
    inst.set('pred_masks', torch.tensor(pred_masks, dtype=torch.bool).cuda())
    return inst


def eval_automatic_annotation(cfg, seg_dir, kp_annot=None):
    def aa2detectron(idx):
        if kp_annot is not None:
            return keypoint2detectron(seg_dir, idx, annots[str(idx)])
        else:
            return part2detectron(seg_dir, idx)

    evaluator = COCOEvaluator(cfg.DATASETS.TEST[0], cfg, False, output_dir=cfg.OUTPUT_DIR)
    evaluator.reset()
    test_loader = build_detection_test_loader(cfg, cfg.DATASETS.TEST[0])

    if kp_annot is not None:
        annots = utils.io.read(kp_annot)
    with torch.no_grad():
        for idx, inputs in enumerate(test_loader):
            img_idx = int(os.path.splitext(os.path.basename(inputs[0]['file_name']))[0])
            outputs = [{'instances': aa2detectron(img_idx)}]
            evaluator.process(inputs, outputs)
    return evaluator.evaluate()


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('-gt', '--gt_annot', required=True, help='Ground truth annotation json file.')
    parser.add_argument('-o', '--out_dir', required=True, help='Output directory path.')
    parser.add_argument('-m', '--model_dir', help='Model directory path.')
    parser.add_argument('-c', '--model_ckpt', help='Model checkpoint name without extension.', default='model_final')
    parser.add_argument('-kp', '--kp_annot', help='Keypoint annotations given by automatic annotation.')
    parser.add_argument('-s', '--seg_dir', help='Segmentation directory generated by automatic annotation.')
    parser.add_argument('-i', '--img_prefix_dir', help='Image prefix directory containing the GT samples.')
    parser.add_argument('--visualize', default=False, action='store_true', help='Whether to visualize results or not.')
    parser.add_argument('--is_part', default=False, action='store_true', help='Whether to evaluate part segmentation or keypoint detection and instance segmentation.')
    return parser.parse_args()


def run(gt_annot, out_dir, model_dir=None, model_ckpt=None, kp_annot=None, seg_dir=None, img_prefix_dir=None, visualize=False, is_part=False):
    assert os.path.isfile(gt_annot)
    assert os.path.isdir(out_dir)
    assert model_dir is None or os.path.isdir(model_dir)
    assert model_dir is not None or os.path.isdir(seg_dir)
    assert img_prefix_dir is None or os.path.isdir(img_prefix_dir)
    assert kp_annot is None or os.path.isfile(kp_annot)

    utils.io.remove(os.path.join(out_dir, 'rat_test_coco_format.json'))
    td2.load_and_register_dataset('rat_test', gt_annot, is_part=is_part, fn_prefix=img_prefix_dir)
    if visualize:
        td2.save_visualization(os.path.join(out_dir, 'gt'), db_name='rat_test')

    cfg = td2.set_model_configuration(out_dir, is_part=is_part)
    if model_dir is not None:
        results, predictor = td2.eval_model(cfg, model_dir=model_dir, model_ckpt=model_ckpt)
        if visualize:
            td2.save_visualization(os.path.join(out_dir, 'pred'), db_name='rat_test', predictor=predictor)
    elif seg_dir is not None:
        results = eval_automatic_annotation(cfg, seg_dir, kp_annot=kp_annot)
    else:
        assert False

    out_fn = os.path.join(out_dir, 'results')
    out_fn += '_bodypart' if is_part else '_keypoint'
    out_fn += '.json'
    utils.io.save(out_fn, results)


if __name__ == "__main__":
    args = parse_args()
    run(**vars(args))